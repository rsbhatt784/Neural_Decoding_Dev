{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example of Kalman Filter decoders\n",
    "\n",
    "This example is similar to those shown in \"Examples_all_decoders.\"\n",
    "However, there is some preprocessing is different for the Kalman, so we have made a separate notebook.\n",
    "\n",
    "In this example notebook, we:\n",
    "1. Import the necessary packages\n",
    "2. Load a data file (spike trains and outputs we are predicting)\n",
    "3. Preprocess the data\n",
    "4. Run the decoders and print the goodness of fit\n",
    "5. Plot example decoded outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Packages\n",
    "\n",
    "Below, we import both standard packages, and functions from the accompanying .py files\n",
    "\n",
    "Note that you may need to specify the path below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## (Configuration) Allows you to return multiple variables from a single cell ##\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Allows you to import files from another folder in current directory ## \n",
    "import os \n",
    "import sys \n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: statsmodels is not installed. You will be unable to use the Naive Bayes Decoder\n",
      "\n",
      "WARNING: Xgboost package is not installed. You will be unable to use the xgboost decoder\n",
      "\n",
      "WARNING: Keras package is not installed. You will be unable to use all neural net decoders\n"
     ]
    }
   ],
   "source": [
    "#Import standard packages\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from scipy import io\n",
    "from scipy import stats\n",
    "import pickle\n",
    "import sys\n",
    "\n",
    "#Import metrics\n",
    "from Neural_Decoding.metrics import get_R2\n",
    "from Neural_Decoding.metrics import get_rho\n",
    "\n",
    "#Import decoder functions\n",
    "from Neural_Decoding.decoders import KalmanFilterDecoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Data\n",
    "The data for this example can be downloaded at this [link](https://www.dropbox.com/s/e9mul73ur9omu5f/example_data_hc.pickle?dl=0).\n",
    "\n",
    "It is the hc-2 dataset from [crcns](https://crcns.org/data-sets/hc/hc-2). Specifically, we use the dataset \"ec014.333\" \n",
    "\n",
    "\n",
    "The data that we load is in the format described below. We have another example notebook, \"Example_format_data_hc\", that may be helpful towards putting the data in this format.\n",
    "\n",
    "Neural data should be a matrix of size \"number of time bins\" x \"number of neurons\", where each entry is the firing rate of a given neuron in a given time bin\n",
    "\n",
    "The output you are decoding should be a matrix of size \"number of time bins\" x \"number of features you are decoding\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1633, 1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(1633, 1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(1633, 90)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Opening Acc/Dec Data \n",
    "folder='/Users/rbhatt6/Documents/MATLAB/' #ENTER THE FOLDER THAT YOUR DATA IS IN\n",
    "\n",
    "# Decoder Velocity Outputs\n",
    "with open(folder+'sortInAccDec.pickle','rb') as f:\n",
    "     sort_In=pickle.load(f,encoding='latin1') \n",
    "with open(folder+'sortOutXAccDec.pickle','rb') as f:\n",
    "     sort_Out_X=pickle.load(f,encoding='latin1') \n",
    "with open(folder+'sortOutYAccDec.pickle','rb') as f:\n",
    "     sort_Out_Y=pickle.load(f,encoding='latin1') \n",
    "\n",
    "# Decoder Position Outputs\n",
    "with open(folder+'sortOutXAccDecPos.pickle','rb') as f:\n",
    "     sort_Out_X_Pos=pickle.load(f,encoding='latin1') \n",
    "with open(folder+'sortOutYAccDecPos.pickle','rb') as f:\n",
    "     sort_Out_Y_Pos=pickle.load(f,encoding='latin1') \n",
    "\n",
    "sort_Out_Y[0].shape\n",
    "sort_Out_Y_Pos[0].shape\n",
    "sort_In[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(sort_In)\n",
    "type(sort_In[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1633, 1)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(1633, 1)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(1632, 1)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(1632,)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(16,)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(1633, 1)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_Acc[0].shape\n",
    "type(X_Acc[0])\n",
    "type(X_Acc)\n",
    "\n",
    "sort_Out_X[0].shape\n",
    "np.diff(sort_Out_X[0], axis = 0).shape\n",
    "np.squeeze(np.diff(sort_Out_X[0], axis = 0)).shape\n",
    "\n",
    "type(sort_Out_X)\n",
    "\n",
    "test = np.array(X_Acc, dtype=object)\n",
    "type(test)\n",
    "test.shape\n",
    "test[0].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1633, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(1633, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Final output is vel, acc, pos\n",
    "\n",
    "X_Comb_Kin = []\n",
    "Y_Comb_Kin = []\n",
    "for i in range(len(sort_Out_X)):\n",
    "    # Concatenating vel with acc for X component\n",
    "    temp1 = (np.diff(sort_Out_X[i], axis = 0))\n",
    "    temp1 = np.concatenate((temp1,temp1[-1:,:]),axis=0)\n",
    "    temp1 = np.array(np.concatenate((sort_Out_X[i], temp1, sort_Out_X_Pos[i]),axis=1))\n",
    "\n",
    "    temp2 = (np.diff(sort_Out_Y[i], axis = 0))\n",
    "    temp2 = np.concatenate((temp2,temp2[-1:,:]),axis=0)\n",
    "    temp2 = np.array(np.concatenate((sort_Out_Y[i], temp2, sort_Out_Y_Pos[i]),axis=1))\n",
    "    X_Comb_Kin.append(temp1)\n",
    "    Y_Comb_Kin.append(temp2)\n",
    "\n",
    "y_kf_X = np.array(X_Comb_Kin, dtype=object)\n",
    "y_kf_Y = np.array(Y_Comb_Kin, dtype=object)\n",
    "\n",
    "# y_kf_X_Comp=np.concatenate((sort_Out_X,X_Acc),axis=0)\n",
    "# y_kf_Y_Comp=np.concatenate((sort_Out_Y,Y_Acc),axis=0)\n",
    "\n",
    "X_Comb_Kin[0].shape\n",
    "Y_Comb_Kin[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1633, 2)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(1633, 2)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Final output is vel, acc\n",
    "\n",
    "X_Acc = []\n",
    "Y_Acc = []\n",
    "for i in range(len(sort_Out_X)):\n",
    "    # Concatenating vel with acc for X component\n",
    "    temp1 = (np.diff(sort_Out_X[i], axis = 0))\n",
    "    temp1 = np.concatenate((temp1,temp1[-1:,:]),axis=0)\n",
    "    temp1 = np.array(np.concatenate((sort_Out_X[i], temp1),axis=1))\n",
    "\n",
    "    temp2 = (np.diff(sort_Out_Y[i], axis = 0))\n",
    "    temp2 = np.concatenate((temp2,temp2[-1:,:]),axis=0)\n",
    "    temp2 = np.array(np.concatenate((sort_Out_Y[i], temp2),axis=1))\n",
    "    X_Acc.append(temp1)\n",
    "    Y_Acc.append(temp2)\n",
    "\n",
    "y_kf_X = np.array(X_Acc, dtype=object)\n",
    "y_kf_Y = np.array(Y_Acc, dtype=object)\n",
    "\n",
    "X_Acc[0].shape\n",
    "Y_Acc[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32,)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#X_Acc = np.empty([16,1])\n",
    "X_Acc = []\n",
    "Y_Acc = []\n",
    "for i in range(len(sort_Out_X)):\n",
    "    temp1 = (np.diff(sort_Out_X[i], axis = 0))\n",
    "    temp1 = np.array(np.concatenate((temp1,temp1[-1:,:]),axis=0))\n",
    "    temp2 = (np.diff(sort_Out_Y[i], axis = 0))\n",
    "    temp2 = np.array(np.concatenate((temp2,temp2[-1:,:]),axis=0))\n",
    "    X_Acc.append(temp1)\n",
    "    Y_Acc.append(temp2)\n",
    "\n",
    "X_Acc = np.array(X_Acc, dtype=object)\n",
    "Y_Acc = np.array(Y_Acc, dtype=object)\n",
    "\n",
    "# y_kf_X_Comp=np.concatenate((sort_Out_X,X_Acc),axis=0)\n",
    "# y_kf_Y_Comp=np.concatenate((sort_Out_Y,Y_Acc),axis=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Preprocess Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3A. User Inputs\n",
    "The user can define what time period to use spikes from (with respect to the output)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lag=0 #What time bin of spikes should be used relative to the output\n",
    "#(lag=-1 means use the spikes 1 bin before the output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3B. Format Covariates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Format Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Remove neurons with too few spikes in HC dataset\n",
    "nd_sum=np.nansum(neural_data,axis=0) #Total number of spikes of each neuron\n",
    "rmv_nrn=np.where(nd_sum<100) #Find neurons who have less than 100 spikes total\n",
    "neural_data=np.delete(neural_data,rmv_nrn,1) #Remove those neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28039, 46)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The covariate is simply the matrix of firing rates for all neurons over time\n",
    "X_kf=neural_data\n",
    "X_kf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Format Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28038, 2)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(28039, 6)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#For the Kalman filter, we use the position, velocity, and acceleration as outputs\n",
    "#Ultimately, we are only concerned with the goodness of fit of position (for this dataset)\n",
    "#But using them all as covariates helps performance\n",
    "\n",
    "#We now determine velocity\n",
    "temp=np.diff(pos_binned,axis=0)\n",
    "vels_binned=np.concatenate((temp,temp[-1:,:]),axis=0)\n",
    "\n",
    "#We now determine acceleration\n",
    "temp2=np.diff(vels_binned,axis=0)\n",
    "acc_binned=np.concatenate((temp2,temp2[-1:,:]),axis=0)\n",
    "\n",
    "y_kf=np.concatenate((pos_binned,vels_binned,acc_binned),axis=1)\n",
    "\n",
    "temp.shape\n",
    "y_kf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Remove time bins with no output (y value)\n",
    "rmv_time=np.where(np.isnan(y_kf[:,0]) | np.isnan(y_kf[:,1]))\n",
    "X_kf=np.delete(X_kf,rmv_time,0)\n",
    "y_kf=np.delete(y_kf,rmv_time,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3C. Take lag into account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_examples=X_kf.shape[0]\n",
    "\n",
    "#Re-align data to take lag into account\n",
    "if lag<0:\n",
    "    y_kf=y_kf[-lag:,:]\n",
    "    X_kf=X_kf[0:num_examples+lag,:]\n",
    "if lag>0:\n",
    "    y_kf=y_kf[0:num_examples-lag,:]\n",
    "    X_kf=X_kf[lag:num_examples,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3D. Split into training/testing/validation sets\n",
    "Note that parameters should be setting using a separate validation set. \n",
    "Then, the goodness of fit should be be tested on a testing set (separate from the training and validation sets)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Set what part of data should be part of the training/testing/validation sets\n",
    "#Note that there was a long period of no movement after about 80% of recording, so I did not use this data.\n",
    "# training_range=[0, 0.5]\n",
    "# valid_range=[0.5,0.65]\n",
    "# testing_range=[0.65, 0.8]\n",
    "\n",
    "training_range=[0, 0.8]\n",
    "valid_range=[0.8,0.9]\n",
    "testing_range=[0.9, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Data: For KF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-21-9f25b06ebb21>:6: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  training_set=np.arange(np.int(np.round(training_range[0]*num_examples_kf))+1,np.int(np.round(training_range[1]*num_examples_kf))-1)\n",
      "<ipython-input-21-9f25b06ebb21>:7: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  testing_set=np.arange(np.int(np.round(testing_range[0]*num_examples_kf))+1,np.int(np.round(testing_range[1]*num_examples_kf))-1)\n",
      "<ipython-input-21-9f25b06ebb21>:8: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  valid_set=np.arange(np.int(np.round(valid_range[0]*num_examples_kf))+1,np.int(np.round(valid_range[1]*num_examples_kf))-1)\n"
     ]
    }
   ],
   "source": [
    "#Number of examples after taking into account bins removed for lag alignment\n",
    "num_examples_kf=X_kf.shape[0]\n",
    "        \n",
    "#Note that each range has a buffer of 1 bin at the beginning and end\n",
    "#This makes it so that the different sets don't include overlapping data\n",
    "training_set=np.arange(np.int(np.round(training_range[0]*num_examples_kf))+1,np.int(np.round(training_range[1]*num_examples_kf))-1)\n",
    "testing_set=np.arange(np.int(np.round(testing_range[0]*num_examples_kf))+1,np.int(np.round(testing_range[1]*num_examples_kf))-1)\n",
    "valid_set=np.arange(np.int(np.round(valid_range[0]*num_examples_kf))+1,np.int(np.round(valid_range[1]*num_examples_kf))-1)\n",
    "\n",
    "#Get training data\n",
    "X_kf_train=X_kf[training_set,:]\n",
    "y_kf_train=y_kf[training_set,:]\n",
    "\n",
    "#Get testing data\n",
    "X_kf_test=X_kf[testing_set,:]\n",
    "y_kf_test=y_kf[testing_set,:]\n",
    "\n",
    "#Get validation data\n",
    "X_kf_valid=X_kf[valid_set,:]\n",
    "y_kf_valid=y_kf[valid_set,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3E. Preprocessing: Normalization and zero-centering\n",
    "We normalize (z_score) the inputs and zero-center the outputs.\n",
    "Parameters for z-scoring (mean/std.) should be determined on the training set only, and then these z-scoring parameters are also used on the testing and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Z-score inputs \n",
    "X_kf_train_mean=np.nanmean(X_kf_train,axis=0)\n",
    "X_kf_train_std=np.nanstd(X_kf_train,axis=0)\n",
    "X_kf_train=(X_kf_train-X_kf_train_mean)/X_kf_train_std\n",
    "X_kf_test=(X_kf_test-X_kf_train_mean)/X_kf_train_std\n",
    "X_kf_valid=(X_kf_valid-X_kf_train_mean)/X_kf_train_std\n",
    "\n",
    "#Zero-center outputs\n",
    "y_kf_train_mean=np.mean(y_kf_train,axis=0)\n",
    "y_kf_train=y_kf_train-y_kf_train_mean\n",
    "y_kf_test=y_kf_test-y_kf_train_mean\n",
    "y_kf_valid=y_kf_valid-y_kf_train_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kalman Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(1633, 2)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(sort_Out_X[0])\n",
    "test = np.concatenate((sort_Out_X[0], sort_Out_Y[0]),1) # concatenate by columns\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf_Rho_Y_Comp = []\n",
    "kf_R2s_Y_Comp = []\n",
    "\n",
    "for i in range(len(sort_In)):\n",
    "    X_kf = sort_In[i]\n",
    "    y_kf = y_kf_X[i]\n",
    "    num_examples_kf=X_kf.shape[0] # nRows (b/c nCols = number of units)\n",
    "\n",
    "    #Note that each range has a buffer of 1 bin at the beginning and end\n",
    "    #This makes it so that the different sets don't include overlapping data\n",
    "    training_set=np.arange(int(np.round(training_range[0]*num_examples_kf))+1,int(np.round(training_range[1]*num_examples_kf))-1)\n",
    "    testing_set=np.arange(int(np.round(testing_range[0]*num_examples_kf))+1,int(np.round(testing_range[1]*num_examples_kf))-1)\n",
    "    valid_set=np.arange(int(np.round(valid_range[0]*num_examples_kf))+1,int(np.round(valid_range[1]*num_examples_kf))-1)\n",
    "\n",
    "    #Get training data\n",
    "    X_kf_train=X_kf[training_set,:]\n",
    "    y_kf_train=y_kf[training_set,:]\n",
    "\n",
    "    #Get testing data\n",
    "    X_kf_test=X_kf[testing_set,:]\n",
    "    y_kf_test=y_kf[testing_set,:]\n",
    "\n",
    "    #Get validation data\n",
    "    X_kf_valid=X_kf[valid_set,:]\n",
    "    y_kf_valid=y_kf[valid_set,:]\n",
    "\n",
    "    #Z-score inputs \n",
    "    X_kf_train_mean=np.nanmean(X_kf_train,axis=0)\n",
    "    X_kf_train_std=np.nanstd(X_kf_train,axis=0)\n",
    "    X_kf_train=(X_kf_train-X_kf_train_mean)/X_kf_train_std\n",
    "    X_kf_test=(X_kf_test-X_kf_train_mean)/X_kf_train_std\n",
    "    X_kf_valid=(X_kf_valid-X_kf_train_mean)/X_kf_train_std\n",
    "\n",
    "    #Zero-center outputs\n",
    "    y_kf_train_mean=np.mean(y_kf_train,axis=0)\n",
    "    y_kf_train=y_kf_train-y_kf_train_mean\n",
    "    y_kf_test=y_kf_test-y_kf_train_mean\n",
    "    y_kf_valid=y_kf_valid-y_kf_train_mean\n",
    "\n",
    "    #Declare model\n",
    "    model_kf=KalmanFilterDecoder(C=1) #There is one optional parameter (see ReadMe)\n",
    "\n",
    "    #Fit model\n",
    "    model_kf.fit(X_kf_train,y_kf_train)\n",
    "\n",
    "    #Get predictions\n",
    "    y_valid_predicted_kf=model_kf.predict(X_kf_valid,y_kf_valid)\n",
    "\n",
    "    #Get metrics of fit (see read me for more details on the differences between metrics)\n",
    "    #First I'll get the R^2\n",
    "    R2_kf=get_R2(y_kf_valid,y_valid_predicted_kf)\n",
    "    #print('R2:',R2_kf[0:2]) #I'm just printing the R^2's of the 1st and 2nd entries that correspond to the positions\n",
    "    kf_R2s_Y_Comp.append(R2_kf)\n",
    "\n",
    "    #Next I'll get the rho^2 (the pearson correlation squared)\n",
    "    rho_kf=get_rho(y_kf_valid,y_valid_predicted_kf)\n",
    "    #print('rho2:',rho_kf[0:2]**2) #I'm just printing the rho^2's of the 1st and 2nd entries that correspond to the positions\n",
    "    kf_Rho_Y_Comp.append(rho_kf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kf_R2s_X_Comp\n",
    "# kf_Rho_X_Comp\n",
    "# kf_R2s_Y_Comp\n",
    "# kf_Rho_Y_Comp\n",
    "\n",
    "# Saving results in a matlab file \n",
    "\n",
    "from scipy.io import savemat\n",
    "import numpy\n",
    "\n",
    "L = [kf_R2s_X_Comp, kf_Rho_X_Comp, kf_R2s_Y_Comp, kf_Rho_Y_Comp]\n",
    "\n",
    "FrameStack = np.empty((4,), dtype=object)\n",
    "for i in range(len(L)):\n",
    "    FrameStack[i] = L[i]\n",
    "\n",
    "savemat(\"KalmanModelOutputs.mat\", {\"KalmanOuputs\":FrameStack})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2: [0.2734179  0.43781231]\n",
      "rho2: [0.31974362 0.45936538]\n"
     ]
    }
   ],
   "source": [
    "#Declare model\n",
    "model_kf=KalmanFilterDecoder(C=5) #There is one optional parameter (see ReadMe)\n",
    "\n",
    "#Fit model\n",
    "model_kf.fit(X_kf_train,y_kf_train)\n",
    "\n",
    "#Get predictions\n",
    "y_valid_predicted_kf=model_kf.predict(X_kf_valid,y_kf_valid)\n",
    "\n",
    "#Get metrics of fit (see read me for more details on the differences between metrics)\n",
    "#First I'll get the R^2\n",
    "R2_kf=get_R2(y_kf_valid,y_valid_predicted_kf)\n",
    "print('R2:',R2_kf[0:2]) #I'm just printing the R^2's of the 1st and 2nd entries that correspond to the positions\n",
    "#Next I'll get the rho^2 (the pearson correlation squared)\n",
    "rho_kf=get_rho(y_kf_valid,y_valid_predicted_kf)\n",
    "print('rho2:',rho_kf[0:2]**2) #I'm just printing the rho^2's of the 1st and 2nd entries that correspond to the positions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Make Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x146514460>]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x146514820>]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#As an example, I plot an example 3000 values of the x position (column index 0), both true and predicted with the Kalman filter\n",
    "#Note that I add back in the mean value, so that both true and predicted values are in the original coordinates\n",
    "fig_x_kf=plt.figure()\n",
    "plt.plot(y_kf_valid[2000:5000,0]+y_kf_train_mean[0],'b')\n",
    "plt.plot(y_valid_predicted_kf[2000:5000,0]+y_kf_train_mean[0],'r')\n",
    "#Save figure\n",
    "# fig_x_kf.savefig('x_position_decoding.eps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
