{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-Bucket Tests on all Acc/Dec and Random Fragments Kalman Filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part A: (1) Import Fragment Data from MATLAB, (2) Save Them in a .pickle file, and (3) Load Them In\n",
    "\n",
    "###### (HOWEVER, YOU DON'T NEED TO LOAD THEM IN AGAIN SINCE STEP 1 ALREADY DOES THAT FOR YOU!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## (Configuration) Allows you to return multiple variables from a single cell ##\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'\n",
    "\n",
    "## Allows you to import files from another folder in current directory ## \n",
    "import os \n",
    "import sys \n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: statsmodels is not installed. You will be unable to use the Naive Bayes Decoder\n",
      "\n",
      "WARNING: Xgboost package is not installed. You will be unable to use the xgboost decoder\n",
      "\n",
      "WARNING: Keras package is not installed. You will be unable to use all neural net decoders\n"
     ]
    }
   ],
   "source": [
    "#Import standard packages\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from scipy import io\n",
    "from scipy import stats\n",
    "import pickle\n",
    "import sys\n",
    "\n",
    "#Import metrics\n",
    "from Neural_Decoding.metrics import get_R2\n",
    "from Neural_Decoding.metrics import get_rho\n",
    "from Neural_Decoding.metrics import get_R2_parts\n",
    "\n",
    "#Import decoder functions\n",
    "from Neural_Decoding.decoders import KalmanFilterDecoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part B: Preprocessing Decoder Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import Data ##\n",
    "# We'll load in position data and derive velocity and acceleration from it \n",
    "\n",
    "# Specify Fragment Types to be used for this anaylsis \n",
    "frag_type = ['AD', 'Rand'] \n",
    "# Specify folder where MATLAB data is stored\n",
    "folder = '/Users/rbhatt6/Documents/MATLAB/' \n",
    "\n",
    " #locals()[\"sortIn\"+frag_type[i]] = io.loadmat(folder+'cleanedSortIn.mat')\n",
    "for i in range(len(frag_type)):\n",
    "    input = \"sortIn_\"+frag_type[i]\n",
    "    locals()[input] = io.loadmat(folder + input + '.mat')\n",
    "\n",
    "    output = \"sortOut_\" + frag_type[i]\n",
    "    locals()[output] = io.loadmat(folder + output + '.mat')\n",
    "\n",
    "    locals()[input] = np.squeeze(list(locals()[input].values())[3])\n",
    "    locals()[output] = np.squeeze(list(locals()[output].values())[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Format Kinematics Data (outputs) ##\n",
    "# For the Kalman filter, we use the position, velocity, and acceleration as outputs.\n",
    "# Ultimately, we are only concerned with the goodness of fit of velocity, but using them all as covariates helps performance.\n",
    "\n",
    "for i in range(len(frag_type)):\n",
    "    # Pulling local variables into new, temp variables\n",
    "    output = locals()[\"sortOut_\"+frag_type[i]]\n",
    "    \n",
    "    # Creating a local variable for each decoder_output\n",
    "    decoder_output = \"decoder_output_\" + frag_type[i]\n",
    "    locals()[decoder_output] = []\n",
    "\n",
    "    for j in range(len(output)): # Number of buckets (i.e. 16 or 8)\n",
    "        nFrags = output[j][0].shape[0]\n",
    "        temp2 = []\n",
    "        for k in range(0, nFrags, 1): # Number of fragments #output[0][0].shape[0]\n",
    "            vel_X = float(output[j][0][k])\n",
    "            vel_Y = float(output[j][1][k])\n",
    "            acc_X = float(output[j][2][k])\n",
    "            acc_Y = float(output[j][3][k])\n",
    "            pos_X = float(output[j][4][k])\n",
    "            pos_Y = float(output[j][5][k])\n",
    "            temp = [vel_X, vel_Y, acc_X, acc_Y, pos_X, pos_Y]\n",
    "            temp2.append(np.array(temp))\n",
    "            #locals()[decoder_output][j][k].append(np.array(temp))\n",
    "        #locals()[decoder_output][j].append(np.array(temp2))\n",
    "        locals()[decoder_output].append(np.array(temp2))\n",
    "        #temp = np.array(np.concatenate((vel_X, vel_Y, acc_X, acc_Y, outputX[j], outputY[j]),axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part C: Partitioning and Running the Kalman Filter on the Same Buckets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (NEW) CROSS-VALIDATED WITHIN-BUCKET TEST (for all 16 buckets)\n",
    "# Doing a 10-fold cross validation procedure\n",
    "\n",
    "# for loop through 10 folds then 16 buckets\n",
    "\n",
    "for i in range(len(frag_type)):\n",
    "\n",
    "   # Pulling local variables \n",
    "   input = locals()[\"sortIn_\"+frag_type[i]]\n",
    "   output = locals()[\"decoder_output_\"+frag_type[i]]\n",
    "\n",
    "   # Creating a local variable to hold final training and testing data \n",
    "   final_X_train = \"final_X_train_\" + frag_type[i]\n",
    "   final_y_train = \"final_y_train_\" + frag_type[i]\n",
    "   final_X_test = \"final_X_test_\" + frag_type[i]\n",
    "   final_y_test = \"final_y_test_\" + frag_type[i]\n",
    "   locals()[final_X_train] = []\n",
    "   locals()[final_y_train] = []\n",
    "   locals()[final_X_test] = []\n",
    "   locals()[final_y_test] = []\n",
    "\n",
    "   idx_list = [0,1,2,3,4,5,6,7,8,9]\n",
    "   # final_X_train = []\n",
    "   # final_y_train = []\n",
    "   # final_X_test = []\n",
    "   # final_y_test = []\n",
    "\n",
    "   # Splitting data for a single bucket into 10 folds - (j) is the left-out fold for testing\n",
    "   for j in range(0,10):\n",
    "      test_idx = j\n",
    "      train_idx = idx_list.copy()\n",
    "      train_idx.pop(j)\n",
    "\n",
    "      temp_X_train = []\n",
    "      temp_y_train = []\n",
    "      temp_X_test = []\n",
    "      temp_y_test = []\n",
    "      \n",
    "      for k in range(len(input)):\n",
    "         X_split = np.array_split(input[k], 10)\n",
    "         y_split = np.array_split(output[k], 10)\n",
    "\n",
    "         # Index the list of indices to create a list of np ndarrays for training (9 arrays) and testing (1 array)\n",
    "         X_train = [X_split[i] for i in train_idx]\n",
    "         X_test = X_split[j]\n",
    "         y_train = [y_split[i] for i in train_idx]\n",
    "         y_test = y_split[j]\n",
    "\n",
    "         # Concatenate the list of 9 arrays for the training sets \n",
    "         X_train = np.concatenate(X_train, axis=0)\n",
    "         y_train = np.concatenate(y_train, axis=0)\n",
    "         \n",
    "         temp_X_train.append(X_train)\n",
    "         temp_y_train.append(y_train)\n",
    "         temp_X_test.append(X_test)\n",
    "         temp_y_test.append(y_test)\n",
    "\n",
    "      locals()[final_X_train].append(temp_X_train)\n",
    "      locals()[final_y_train].append(temp_y_train)\n",
    "      locals()[final_X_test].append(temp_X_test)\n",
    "      locals()[final_y_test].append(temp_y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check for Decoder Accuracy\n",
    "### Training on 15 buckets and Testing on 1 bucket instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only using velocity \n",
    "## Format Kinematics Data (outputs) ##\n",
    "# For the Kalman filter, we use the position, velocity, and acceleration as outputs.\n",
    "# Ultimately, we are only concerned with the goodness of fit of velocity, but using them all as covariates helps performance.\n",
    "\n",
    "for i in range(len(frag_type)):\n",
    "    # Pulling local variables into new, temp variables\n",
    "    output = locals()[\"sortOut_\"+frag_type[i]]\n",
    "    \n",
    "    # Creating a local variable for each decoder_output\n",
    "    decoder_output = \"decoder_output_\" + frag_type[i]\n",
    "    locals()[decoder_output] = []\n",
    "\n",
    "    for j in range(len(output)): # Number of buckets (i.e. 16 or 8)\n",
    "        nFrags = output[j][0].shape[0]\n",
    "        temp2 = []\n",
    "        for k in range(0, nFrags, 1): # Number of fragments #output[0][0].shape[0]\n",
    "            vel_X = float(output[j][0][k])\n",
    "            vel_Y = float(output[j][1][k])\n",
    "            temp = [vel_X, vel_Y]\n",
    "            temp2.append(np.array(temp))\n",
    "        locals()[decoder_output].append(np.array(temp2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listArrays = final_y_test_AD[0][0:3]\n",
    "listArrays\n",
    "\n",
    "sampleList = [1,2]\n",
    "\n",
    "slipList = [listArrays[i] for i in sampleList]\n",
    "slip = np.concatenate(slipList, axis=0)\n",
    "\n",
    "len(slipList)\n",
    "slip.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Within-Bucket Test with 10-fold Cross-Validation \n",
    "from Neural_Decoding.runModelsKF import run_model_kf_test\n",
    "\n",
    "for i in range(len(frag_type)):\n",
    "\n",
    "    # Pulling local variables \n",
    "    frag_X_train =  locals()[\"final_X_train_\" + frag_type[i]]\n",
    "    frag_y_train = locals()[\"final_y_train_\" + frag_type[i]]\n",
    "    frag_X_test = locals()[\"final_X_test_\" + frag_type[i]]\n",
    "    frag_y_test = locals()[\"final_y_test_\" + frag_type[i]]\n",
    "\n",
    "    # Creating a local variable to hold predicted outputs for each frag type AND their trained models\n",
    "    parts = \"pred_parts_\" + frag_type[i]\n",
    "    models = \"more_trained_models_\" + frag_type[i]\n",
    "    locals()[parts] = []\n",
    "    locals()[models] = []\n",
    "\n",
    "    for cross in range(0,10):\n",
    "        X_train = frag_X_train[cross]\n",
    "        y_train = frag_y_train[cross]\n",
    "        X_test = frag_X_test[cross]\n",
    "        y_test = frag_y_test[cross]\n",
    "        \n",
    "        curr_R2s, curr_models = run_model_kf_test(X_train, y_train, X_test,y_test, \"parts\")\n",
    "        locals()[parts].append(curr_R2s)\n",
    "        locals()[models].append(curr_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Within-Bucket combined XY_FVAF \n",
    "# For velocity only, although all kinematic variables should be used for model-fitting and predicted for.\n",
    "from Neural_Decoding.metrics import compute_XY_FVAF\n",
    "\n",
    "# 'pred_parts_AD' was thankfully also a list of arrays containing the R2s\n",
    "\n",
    "for i in range(len(frag_type)):\n",
    "\n",
    "    # Pulling local variables (computed R2s for parts)\n",
    "    R2s_parts = locals()[\"pred_parts_\" + frag_type[i]]\n",
    "\n",
    "    # Creating a local variable to hold final XY_FVAFs\n",
    "    XY_FVAFs = \"XY_FVAFs_\" + frag_type[i]\n",
    "    locals()[XY_FVAFs] = []\n",
    "\n",
    "    for j in range(0,10):\n",
    "        curr_fold = R2s_parts[j]\n",
    "\n",
    "        curr_fold_XY_FVAFs = []\n",
    "        for k in range(0,16):\n",
    "            #curr_bucket = Kalman_R2s_combined[i]\n",
    "            vel_x_nom = curr_fold[k][0][0] # dim = (curr_bucket, nom, x_vel)\n",
    "            vel_x_denom = curr_fold[k][1][0] # dim = (curr_bucket, denom, x_vel)\n",
    "            vel_y_nom = curr_fold[k][0][1] # dim = (curr_bucket, nom, y_vel)\n",
    "            vel_y_denom = curr_fold[k][1][1] # dim = (curr_bucket, denom, y_vel)\n",
    "\n",
    "            XY_FVAF = compute_XY_FVAF(vel_x_nom,vel_x_denom,vel_y_nom,vel_y_denom)\n",
    "            curr_fold_XY_FVAFs.append(XY_FVAF)\n",
    "\n",
    "        locals()[XY_FVAFs].append(curr_fold_XY_FVAFs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.18562900105147018,\n",
       "  0.11542580820668069,\n",
       "  0.14123323914564356,\n",
       "  0.1313249399239147,\n",
       "  0.1974403498660241,\n",
       "  0.0029681292454749597,\n",
       "  0.20849075893882985,\n",
       "  0.05959470863125993,\n",
       "  0.14046321475732793,\n",
       "  0.17872962490255695,\n",
       "  0.13008646104343358,\n",
       "  0.1927348175191157,\n",
       "  0.17399811911594398,\n",
       "  0.13387619839980203,\n",
       "  0.15954570513771016,\n",
       "  0.14636177034759967],\n",
       " [0.18084049553881032,\n",
       "  0.12176030103338886,\n",
       "  0.11298028646593272,\n",
       "  0.23069395927643754,\n",
       "  0.12237708560429039,\n",
       "  0.14633100004262722,\n",
       "  0.1269378710978284,\n",
       "  0.155954339747563,\n",
       "  0.1814380294186857,\n",
       "  0.1319703924676895,\n",
       "  0.14234371114066724,\n",
       "  0.17866867982857026,\n",
       "  0.1364621895977428,\n",
       "  0.1001449985368188,\n",
       "  0.12425811864372249,\n",
       "  0.19306484986961447],\n",
       " [0.08422297037867799,\n",
       "  0.18584488075654115,\n",
       "  0.09239303075379424,\n",
       "  0.10232419107315383,\n",
       "  0.14380886267649573,\n",
       "  0.2101714375241409,\n",
       "  0.16997241843795674,\n",
       "  0.22036072467993728,\n",
       "  0.1462147725184949,\n",
       "  0.1334439546994769,\n",
       "  0.1167580351026859,\n",
       "  0.15990113833570563,\n",
       "  0.07617280818288008,\n",
       "  0.22499431621338217,\n",
       "  0.1423366289923148,\n",
       "  0.17815926538268578],\n",
       " [0.1557420590989298,\n",
       "  0.20464692671208828,\n",
       "  0.20820417750353504,\n",
       "  0.19811043233990067,\n",
       "  0.14723531845435167,\n",
       "  0.06545133314332074,\n",
       "  0.0947296779938338,\n",
       "  0.12343295711461322,\n",
       "  0.136515222135552,\n",
       "  0.23100214014140008,\n",
       "  0.14533708898375186,\n",
       "  0.10649646510876565,\n",
       "  0.1708926781070419,\n",
       "  0.14580208780983872,\n",
       "  0.16600811575499919,\n",
       "  0.24944111637784927],\n",
       " [0.08749983180907228,\n",
       "  0.13628815099275848,\n",
       "  0.19210609875785323,\n",
       "  0.10045108400965119,\n",
       "  0.19914310869509155,\n",
       "  0.14349994693121626,\n",
       "  0.21867279596467737,\n",
       "  0.21453255412894678,\n",
       "  0.20199893404862623,\n",
       "  0.07281293228743035,\n",
       "  0.09081371639405089,\n",
       "  0.108727299291704,\n",
       "  0.06667117012898782,\n",
       "  0.07053190715878044,\n",
       "  0.1024412784251908,\n",
       "  0.16290259836746568],\n",
       " [0.05778053178055753,\n",
       "  0.22537760350796954,\n",
       "  0.2322886361922465,\n",
       "  0.1197770595817117,\n",
       "  0.11636005045909636,\n",
       "  0.16718539657450004,\n",
       "  0.09138575042957331,\n",
       "  0.1196383029371253,\n",
       "  0.18049701975802523,\n",
       "  0.08592859287812726,\n",
       "  0.17742427823466933,\n",
       "  0.1020895155595587,\n",
       "  0.07914867257346925,\n",
       "  0.1336827231355907,\n",
       "  0.25515335564212227,\n",
       "  0.22924515524325006],\n",
       " [0.08044787281631505,\n",
       "  0.09209356107017319,\n",
       "  0.12787765301551568,\n",
       "  0.15627707781873346,\n",
       "  0.14688058174499652,\n",
       "  0.10470751276016055,\n",
       "  0.14397384107032862,\n",
       "  0.07540234814181423,\n",
       "  0.18333897490079654,\n",
       "  0.15185989613771367,\n",
       "  0.11857560350594787,\n",
       "  0.13283013380669828,\n",
       "  0.15483478334888023,\n",
       "  0.09513459823703307,\n",
       "  0.17055566017248303,\n",
       "  0.19086407856598908],\n",
       " [0.1373264145405927,\n",
       "  0.2034394948473287,\n",
       "  0.07901406456667937,\n",
       "  0.16582940272242264,\n",
       "  0.22350540724031098,\n",
       "  0.24239210859310945,\n",
       "  0.22177167771483708,\n",
       "  0.09031067244877,\n",
       "  0.08934153453340177,\n",
       "  0.16275483546798308,\n",
       "  0.24355911747423264,\n",
       "  0.12689825530033194,\n",
       "  0.13087919713083174,\n",
       "  0.1739695741270837,\n",
       "  0.25458667867629514,\n",
       "  0.07150131536983984],\n",
       " [-0.002716543759061052,\n",
       "  0.10199007616716227,\n",
       "  0.19778019315281137,\n",
       "  0.16731213895408314,\n",
       "  0.1124524326454529,\n",
       "  0.2337251452608029,\n",
       "  0.2513197001493497,\n",
       "  0.137077579901291,\n",
       "  0.10696037021340654,\n",
       "  0.21800714064365656,\n",
       "  0.1060352415881961,\n",
       "  0.20021210642305787,\n",
       "  0.1363904599274911,\n",
       "  0.19388622311654702,\n",
       "  0.17548371587863465,\n",
       "  0.19781217424873365],\n",
       " [0.24546342254046138,\n",
       "  0.06596065511045257,\n",
       "  0.07194854148494467,\n",
       "  0.12250422493076785,\n",
       "  0.11311262224762952,\n",
       "  0.1857474509939644,\n",
       "  0.27137090296326916,\n",
       "  0.22810008344224197,\n",
       "  0.18012947734927587,\n",
       "  0.15772912490920832,\n",
       "  0.14572019985551743,\n",
       "  0.13743511978353684,\n",
       "  0.06296359042887978,\n",
       "  0.1436268015114186,\n",
       "  0.11310882165199976,\n",
       "  0.24091622990808503]]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XY_FVAFs_Rand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Testing Models on Same Bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (NEW) Within-Bucket Test with 10-fold Cross-Validation \n",
    "from Neural_Decoding.runModelsKF import run_model_kf_cv\n",
    "\n",
    "for i in range(len(frag_type)):\n",
    "\n",
    "    # Pulling local variables \n",
    "    frag_X_train =  locals()[\"final_X_train_\" + frag_type[i]]\n",
    "    frag_y_train = locals()[\"final_y_train_\" + frag_type[i]]\n",
    "    frag_X_test = locals()[\"final_X_test_\" + frag_type[i]]\n",
    "    frag_y_test = locals()[\"final_y_test_\" + frag_type[i]]\n",
    "\n",
    "    # Creating a local variable to hold predicted outputs for each frag type AND their trained models\n",
    "    parts = \"pred_parts_\" + frag_type[i]\n",
    "    models = \"models_\" + frag_type[i]\n",
    "    locals()[parts] = []\n",
    "    locals()[models] = []\n",
    "\n",
    "    for cross in range(0,10):\n",
    "        X_train = frag_X_train[cross]\n",
    "        y_train = frag_y_train[cross]\n",
    "        X_test = frag_X_test[cross]\n",
    "        y_test = frag_y_test[cross]\n",
    "        \n",
    "        curr_R2s, curr_models = run_model_kf_cv(X_train, y_train, X_test,y_test, \"parts\")\n",
    "        locals()[parts].append(curr_R2s)\n",
    "        locals()[models].append(curr_models)\n",
    "\n",
    "\n",
    "# len(within_bucket_R2s) # 10\n",
    "# len(within_bucket_R2s[0]) # 16\n",
    "# within_bucket_R2s[0][0] # each fold has R2s (vel,pos,acc) for each of the 16 buckets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (NEW) Compute Within-Bucket combined XY_FVAF \n",
    "# For velocity only, although all kinematic variables should be used for model-fitting and predicted for.\n",
    "from Neural_Decoding.metrics import compute_XY_FVAF\n",
    "\n",
    "# 'pred_parts_AD' was thankfully also a list of arrays containing the R2s\n",
    "\n",
    "for i in range(len(frag_type)):\n",
    "\n",
    "    # Pulling local variables (computed R2s for parts)\n",
    "    R2s_parts = locals()[\"pred_parts_\" + frag_type[i]]\n",
    "\n",
    "    # Creating a local variable to hold final XY_FVAFs\n",
    "    XY_FVAFs = \"XY_FVAFs_\" + frag_type[i]\n",
    "    locals()[XY_FVAFs] = []\n",
    "\n",
    "    for j in range(0,10):\n",
    "        curr_fold = R2s_parts[j]\n",
    "\n",
    "        curr_fold_XY_FVAFs = []\n",
    "        for k in range(0,16):\n",
    "            #curr_bucket = Kalman_R2s_combined[i]\n",
    "            vel_x_nom = curr_fold[k][0][0] # dim = (curr_bucket, nom, x_vel)\n",
    "            vel_x_denom = curr_fold[k][1][0] # dim = (curr_bucket, denom, x_vel)\n",
    "            vel_y_nom = curr_fold[k][0][1] # dim = (curr_bucket, nom, y_vel)\n",
    "            vel_y_denom = curr_fold[k][1][1] # dim = (curr_bucket, denom, y_vel)\n",
    "\n",
    "            XY_FVAF = compute_XY_FVAF(vel_x_nom,vel_x_denom,vel_y_nom,vel_y_denom)\n",
    "            curr_fold_XY_FVAFs.append(XY_FVAF)\n",
    "\n",
    "        locals()[XY_FVAFs].append(curr_fold_XY_FVAFs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[[-0.05895855148404672,\n",
       "  0.010978191002686044,\n",
       "  0.10898105720874696,\n",
       "  0.15252195200948193,\n",
       "  0.12347172654056748,\n",
       "  -0.031815910410450954,\n",
       "  0.13814005773006188,\n",
       "  -0.12992251564687107,\n",
       "  0.12175602870352797,\n",
       "  0.14131231211390294,\n",
       "  0.1197542515963329,\n",
       "  0.1823304161448034,\n",
       "  0.057876195903714955,\n",
       "  0.03221324161886374,\n",
       "  0.05581837340284246,\n",
       "  0.08186843974526337],\n",
       " [0.15092966717990974,\n",
       "  -0.09275244951760309,\n",
       "  -0.0014020753443959588,\n",
       "  0.1839716307426853,\n",
       "  0.08280792239530432,\n",
       "  0.10005861272219019,\n",
       "  0.1299987521605943,\n",
       "  0.09826350506714154,\n",
       "  0.1690824906382108,\n",
       "  0.14188143609057058,\n",
       "  -0.08099711353613959,\n",
       "  0.1375089915318154,\n",
       "  0.08616030652559548,\n",
       "  -0.11906328117216591,\n",
       "  0.01013442089746519,\n",
       "  0.16797685286419195],\n",
       " [0.06189112211975345,\n",
       "  0.07928723156763495,\n",
       "  0.007062119315380921,\n",
       "  0.0632305167303786,\n",
       "  0.0902631494705266,\n",
       "  0.1748850042780259,\n",
       "  0.08184488356907327,\n",
       "  0.1504108106453631,\n",
       "  0.1289821975512776,\n",
       "  0.16676589340946724,\n",
       "  0.0202084090911423,\n",
       "  0.13636815096922272,\n",
       "  -0.019452672186695885,\n",
       "  0.08771543478667154,\n",
       "  0.09778884602573634,\n",
       "  0.12268177513310297],\n",
       " [0.0009707156322767974,\n",
       "  0.20355129784658554,\n",
       "  0.1278994346671407,\n",
       "  0.19647293110950426,\n",
       "  0.13861227720125557,\n",
       "  0.04666619812900541,\n",
       "  0.035759709252131344,\n",
       "  0.0027985378056910593,\n",
       "  0.09761879390251516,\n",
       "  0.19551885371210043,\n",
       "  0.09489753420313074,\n",
       "  0.10102721341650633,\n",
       "  0.09133198032847134,\n",
       "  0.12180899445073834,\n",
       "  0.08062910170587556,\n",
       "  0.2020905421019391],\n",
       " [0.03232503976489831,\n",
       "  0.03464600369869186,\n",
       "  0.12945916247920985,\n",
       "  0.07292570478350924,\n",
       "  0.17383839468645057,\n",
       "  0.1085251377860803,\n",
       "  0.1917577229205808,\n",
       "  0.22542179552021058,\n",
       "  0.16873560151705136,\n",
       "  0.034970100901688284,\n",
       "  0.07184223643067345,\n",
       "  0.09478613768984301,\n",
       "  0.026663291992377047,\n",
       "  0.0008022518470145457,\n",
       "  0.009051207689960039,\n",
       "  0.01531058228358484],\n",
       " [-0.2978549868028253,\n",
       "  -0.025212311467201376,\n",
       "  0.16598766846178759,\n",
       "  0.06184944464785025,\n",
       "  0.06617211423525982,\n",
       "  0.14669357269050476,\n",
       "  0.08647456945003129,\n",
       "  -0.019795011658589434,\n",
       "  0.1536407040932155,\n",
       "  0.04289539684241095,\n",
       "  0.13340057094737368,\n",
       "  0.10916057824612035,\n",
       "  -0.10120207825782201,\n",
       "  0.015695802677514914,\n",
       "  0.18602472274100057,\n",
       "  0.19022798281368514],\n",
       " [-0.014285418003851191,\n",
       "  -0.04855426541964669,\n",
       "  0.04272178777583935,\n",
       "  0.0810059348392641,\n",
       "  0.11982620450196912,\n",
       "  0.07039524237893602,\n",
       "  0.06532908926574499,\n",
       "  -0.14760117553395058,\n",
       "  0.1786176591757508,\n",
       "  0.08849639852174973,\n",
       "  0.11419910531223243,\n",
       "  0.009435208374065529,\n",
       "  0.046322752416984025,\n",
       "  0.031474981452725426,\n",
       "  0.08265091666741664,\n",
       "  0.15097103584457772],\n",
       " [0.02231734154537579,\n",
       "  0.14819553635782867,\n",
       "  0.02402328619840699,\n",
       "  0.11496548454212618,\n",
       "  0.19022334952578213,\n",
       "  0.2033670538871173,\n",
       "  0.13834882045363206,\n",
       "  0.08954076251607934,\n",
       "  0.07281509353747928,\n",
       "  0.15811103625098988,\n",
       "  0.1980021381174485,\n",
       "  0.06327135262830752,\n",
       "  0.048894569674402644,\n",
       "  0.12173659376840851,\n",
       "  0.15594359305792316,\n",
       "  0.017710304513285813],\n",
       " [0.03802816475155857,\n",
       "  0.037466613549567596,\n",
       "  0.18430160203647095,\n",
       "  0.13839551550456297,\n",
       "  0.09209058610470422,\n",
       "  0.15390879635435784,\n",
       "  0.24699642913319897,\n",
       "  0.11302335079096426,\n",
       "  0.07302381116374179,\n",
       "  0.18784112050894075,\n",
       "  -0.15306616809452245,\n",
       "  0.09389610327569375,\n",
       "  0.046002761471151454,\n",
       "  0.249432024135244,\n",
       "  0.08179270260791272,\n",
       "  0.15753868391817338],\n",
       " [0.07759685626433166,\n",
       "  0.01573533209535094,\n",
       "  0.01934550053116879,\n",
       "  0.04465647088921587,\n",
       "  0.049463209442839995,\n",
       "  0.16889825389397772,\n",
       "  0.18541343211921157,\n",
       "  0.13717213723645916,\n",
       "  0.13519012653892093,\n",
       "  0.09022049005364541,\n",
       "  0.1088544047318788,\n",
       "  0.08321497009231882,\n",
       "  0.008452108995569807,\n",
       "  -0.013159052413825867,\n",
       "  0.04042295047082678,\n",
       "  0.2071637761023093]]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(XY_FVAFs_Rand)\n",
    "len(XY_FVAFs_Rand[0])\n",
    "\n",
    "XY_FVAFs_Rand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-Bucket Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (NEW) Opposite-polarity, Opposite-direction, Complete-opposite and Full cross-bucket tests\n",
    "from Neural_Decoding.runModelsKF import opposite_polarity_test_cv, complete_opposite_bucket_test_cv, opposite_direction_test_cv, cross_buckets_test_cv\n",
    "\n",
    "for i in range(len(frag_type)):\n",
    "\n",
    "    # Pulling local variables \n",
    "    frag_X_test = locals()[\"final_X_test_\" + frag_type[i]]\n",
    "    frag_y_test = locals()[\"final_y_test_\" + frag_type[i]]\n",
    "    models = locals()[\"models_\" + frag_type[i]]\n",
    "\n",
    "    # Creating a local variable to hold FVAFs\n",
    "    opposite_polarity = \"opposite_polarity_FVAFs_\" + frag_type[i]\n",
    "    opposite_direction = \"opposite_direction_FVAFs_\" + frag_type[i]\n",
    "    complete_opposite = \"complete_opposite_FVAFs_\" + frag_type[i]\n",
    "    cross_buckets = \"cross_buckets_FVAFs_\" + frag_type[i]\n",
    "    locals()[opposite_polarity] = []\n",
    "    locals()[opposite_direction] = []\n",
    "    locals()[complete_opposite] = []\n",
    "    locals()[cross_buckets] = []\n",
    "\n",
    "\n",
    "    for j in range(0,10):\n",
    "        curr_models = models[j]\n",
    "        curr_X_test = frag_X_test[j]\n",
    "        curr_y_test = frag_y_test[j]\n",
    "\n",
    "        # Creating a local variable to hold opposite-polarity and complete-opposite FVAFs\n",
    "        locals()[opposite_polarity].append(opposite_polarity_test_cv(curr_models, curr_X_test, curr_y_test, \"parts\", frag_type[i]))\n",
    "        locals()[opposite_direction].append(opposite_direction_test_cv(curr_models, curr_X_test, curr_y_test, \"parts\", frag_type[i]))\n",
    "        locals()[complete_opposite].append(complete_opposite_bucket_test_cv(curr_models, curr_X_test, curr_y_test, \"parts\", frag_type[i]))\n",
    "        locals()[cross_buckets].append(cross_buckets_test_cv(curr_models, curr_X_test, curr_y_test, \"parts\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (NEW) Opposite-polarity, Opposite-direction\n",
    "from Neural_Decoding.runModelsKF import opposite_polarity_test_cv, opposite_direction_test_cv\n",
    "\n",
    "for i in range(len(frag_type)):\n",
    "\n",
    "    # Pulling local variables \n",
    "    frag_X_test = locals()[\"final_X_test_\" + frag_type[i]]\n",
    "    frag_y_test = locals()[\"final_y_test_\" + frag_type[i]]\n",
    "    models = locals()[\"models_\" + frag_type[i]]\n",
    "\n",
    "    # Creating a local variable to hold FVAFs\n",
    "    opposite_polarity = \"opposite_polarity_FVAFs_\" + frag_type[i]\n",
    "    opposite_direction = \"opposite_direction_FVAFs_\" + frag_type[i]\n",
    "    locals()[opposite_polarity] = []\n",
    "    locals()[opposite_direction] = []\n",
    "\n",
    "    for j in range(0,10):\n",
    "        curr_models = models[j]\n",
    "        curr_X_test = frag_X_test[j]\n",
    "        curr_y_test = frag_y_test[j]\n",
    "\n",
    "        # Creating a local variable to hold opposite-polarity and complete-opposite FVAFs\n",
    "        locals()[opposite_polarity].append(opposite_polarity_test_cv(curr_models, curr_X_test, curr_y_test, \"parts\", frag_type[i]))\n",
    "        locals()[opposite_direction].append(opposite_direction_test_cv(curr_models, curr_X_test, curr_y_test, \"parts\", frag_type[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.596511754937795,\n",
       " -0.845377633796287,\n",
       " -0.5442052571835376,\n",
       " -0.6402684110153221,\n",
       " -0.8483529719343958,\n",
       " -0.5859790203411999,\n",
       " -0.8896922706650932,\n",
       " -0.579429367491493,\n",
       " -1.6662139961343092,\n",
       " -1.106784215383617,\n",
       " -0.522514916313269,\n",
       " -0.3016188123692447,\n",
       " -0.43763546376836904,\n",
       " -0.4207705093701606,\n",
       " -0.6720919195891486,\n",
       " -1.0339851259396013]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[-4.6676544329462235,\n",
       " -2.761034471579671,\n",
       " -3.476972390605133,\n",
       " -5.0486321668350165,\n",
       " -8.033987228362749,\n",
       " -5.708250846850241,\n",
       " -4.500824959062539,\n",
       " -4.03310552516325,\n",
       " -6.7133562521038685,\n",
       " -3.5940393315757104,\n",
       " -3.4620686490262083,\n",
       " -4.330984164207452,\n",
       " -5.151195240857863,\n",
       " -6.420394788951712,\n",
       " -4.713492347945885,\n",
       " -5.638184388273333]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opposite_polarity_FVAFs_AD[0]\n",
    "opposite_direction_FVAFs_AD[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part D: Partitioning and Running the Kalman Filter on Separate Training and Test Buckets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part E: Save all outputs (i.e. FVAFs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving results in a matlab file \n",
    "from scipy.io import savemat\n",
    "\n",
    "result1 = [XY_FVAFs_AD, XY_FVAFs_Rand]\n",
    "result2 = [cross_buckets_FVAFs_AD, cross_buckets_FVAFs_Rand]\n",
    "result3 = [opposite_polarity_FVAFs_AD, opposite_polarity_FVAFs_Rand]\n",
    "result4 = [opposite_direction_FVAFs_AD, opposite_direction_FVAFs_Rand]\n",
    "result5 = [complete_opposite_FVAFs_AD, complete_opposite_FVAFs_Rand]\n",
    "\n",
    "FrameStack1 = np.empty((2,), dtype=object)\n",
    "FrameStack2 = np.empty((2,), dtype=object)\n",
    "FrameStack3 = np.empty((2,), dtype=object)\n",
    "FrameStack4 = np.empty((2,), dtype=object)\n",
    "FrameStack5 = np.empty((2,), dtype=object)\n",
    "for i in range(len(result1)):\n",
    "    FrameStack1[i] = result1[i]\n",
    "    FrameStack2[i] = result2[i]\n",
    "    FrameStack3[i] = result3[i]\n",
    "    FrameStack4[i] = result4[i]\n",
    "    FrameStack5[i] = result5[i]\n",
    "savemat(\"Within_Bucket.mat\", {\"XY_FVAF\":FrameStack1})\n",
    "savemat(\"Cross_Bucket.mat\", {\"Cross_Bucket\":FrameStack2})\n",
    "savemat(\"Opposite_Polarity.mat\", {\"Opposite_Polarity\":FrameStack3})\n",
    "savemat(\"Opposite_Direction.mat\", {\"Opposite_Direction\":FrameStack4})\n",
    "savemat(\"Complete_Opposite.mat\", {\"Complete_Opposite\":FrameStack5})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(sortIn_AD)):\n",
    "    X_kf = sortIn_AD[i]\n",
    "    y_kf = decoder_output_AD[i]\n",
    "    num_examples_kf=X_kf.shape[0] # nRows (b/c nCols = number of units)\n",
    "    \n",
    "    #Note that each range has a buffer of 1 bin at the beginning and end\n",
    "    #This makes it so that the different sets don't include overlapping data\n",
    "    training_set=np.arange(int(np.round(training_range[0]*num_examples_kf))+1,int(np.round(training_range[1]*num_examples_kf))-1)\n",
    "    testing_set=np.arange(int(np.round(testing_range[0]*num_examples_kf))+1,int(np.round(testing_range[1]*num_examples_kf))-1)\n",
    "    valid_set=np.arange(int(np.round(valid_range[0]*num_examples_kf))+1,int(np.round(valid_range[1]*num_examples_kf))-1)\n",
    "\n",
    "    #Get training data\n",
    "    X_kf_train=X_kf[training_set,:]\n",
    "    y_kf_train=y_kf[training_set,:]\n",
    "\n",
    "    #Get testing data\n",
    "    X_kf_test=X_kf[testing_set,:]\n",
    "    y_kf_test=y_kf[testing_set,:]\n",
    "\n",
    "    #Get validation data\n",
    "    X_kf_valid=X_kf[valid_set,:]\n",
    "    y_kf_valid=y_kf[valid_set,:]\n",
    "\n",
    "    #Z-score inputs \n",
    "    X_kf_train_mean=np.nanmean(X_kf_train,axis=0)\n",
    "    X_kf_train_std=np.nanstd(X_kf_train,axis=0)\n",
    "    X_kf_train=(X_kf_train-X_kf_train_mean)/X_kf_train_std\n",
    "    X_kf_test=(X_kf_test-X_kf_train_mean)/X_kf_train_std\n",
    "    X_kf_valid=(X_kf_valid-X_kf_train_mean)/X_kf_train_std\n",
    "\n",
    "    #Zero-center outputs\n",
    "    y_kf_train_mean=np.mean(y_kf_train,axis=0)\n",
    "    y_kf_train=y_kf_train-y_kf_train_mean\n",
    "    y_kf_test=y_kf_test-y_kf_train_mean\n",
    "    y_kf_valid=y_kf_valid-y_kf_train_mean\n",
    "\n",
    "    #Declare model\n",
    "    model_kf=KalmanFilterDecoder(C=1) #There is one optional parameter (see ReadMe)\n",
    "\n",
    "    #Fit model\n",
    "    model_kf.fit(X_kf_train,y_kf_train)\n",
    "\n",
    "    #Get predictions\n",
    "    y_valid_predicted_kf=model_kf.predict(X_kf_valid,y_kf_valid)\n",
    "\n",
    "    #Get metrics of fit (see read me for more details on the differences between metrics)\n",
    "    #First I'll get the R^2\n",
    "    R2_kf=get_R2(y_kf_valid,y_valid_predicted_kf)\n",
    "    print('R2:',R2_kf[0:2]) #I'm just printing the R^2's of the 1st and 2nd entries that correspond to the positions\n",
    "    #Next I'll get the rho^2 (the pearson correlation squared)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
